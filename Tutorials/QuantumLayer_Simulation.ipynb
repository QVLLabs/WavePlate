{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxxnfogZPDJP"
      },
      "outputs": [],
      "source": [
        "!pip install waveplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJEpoK7YPNvz"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import math\n",
        "import cmath\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from waveplate import *\n",
        "\n",
        "# %%\n",
        "n_qubits = 1\n",
        "q_depth = 2\n",
        "q_delta = 0.01\n",
        "\n",
        "\n",
        "# %%\n",
        "def quantum_layer(q_input_features, q_weights_flat):\n",
        "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
        "\n",
        "    qc = PhtotonicCircuit()\n",
        "    qc.HWP(22.5)\n",
        "    for idx, angle in enumerate(q_input_features):\n",
        "        qc.HWP(angle, idx)\n",
        "\n",
        "    for layer in range(q_depth):\n",
        "        for idx, angle in enumerate(q_weights[layer]):\n",
        "            qc.HWP(angle, idx)\n",
        "\n",
        "    return qc.Z_expectation(shots=20)[2]  # we should decide how many shots\n",
        "\n",
        "def run(q_weights):\n",
        "    qc = PhtotonicCircuit()\n",
        "    qc.HWP(22.5)\n",
        "\n",
        "    for idx, angle in enumerate(q_weights):\n",
        "        qc.HWP(angle, idx)\n",
        "\n",
        "    return qc.Z_expectation(shots=20)[2]  # we should decide how many shots\n",
        "\n",
        "def apply_gradient(params):\n",
        "    params = params.tolist()\n",
        "    s = np.pi/2\n",
        "    gradient = []\n",
        "    for k in params:\n",
        "        k_plus = k + s\n",
        "        k_minus = k - s\n",
        "        exp_plus = run([k_plus])\n",
        "        exp_minus = run([k_minus])\n",
        "        gr = (exp_plus - exp_minus) / 2\n",
        "        gradient.append(gr)\n",
        "    return torch.tensor(gradient,dtype=torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "    ])\n",
        "}\n",
        "\n",
        "# %%\n",
        "data_dir = 'YOUR PATH'\n",
        "image_datasets = {'train': datasets.ImageFolder(os.path.join(data_dir, 'train'),\n",
        "                                                data_transforms['train'])}\n",
        "dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=1,\n",
        "                                                    shuffle=True)}\n",
        "dataset_sizes = {'train': len(image_datasets['train'])}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# %%\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
        "        self.fc1 = nn.Linear(32 * 54 * 54, 1200)\n",
        "        self.fc2 = nn.Linear(1200, 120)\n",
        "        self.fc3 = nn.Linear(120, 84)\n",
        "        self.fc4 = nn.Linear(84, 2)\n",
        "        self.q_params = torch.nn.Parameter( q_delta * torch.randn(2,dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 54 * 54)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        print(self.q_params)\n",
        "        q_out = None\n",
        "        for elem in x:\n",
        "            # print(elem)\n",
        "            q_out_elem = quantum_layer(elem, self.q_params)\n",
        "            if q_out == None:\n",
        "                q_out = torch.tensor([[q_out_elem]])\n",
        "            else:\n",
        "                q_out = torch.add(q_out, torch.tensor([[q_out_elem]]))\n",
        "\n",
        "        q_out = (q_out+1)/2\n",
        "        q_out = torch.cat((q_out, 1-q_out), -1)\n",
        "        q_out = q_out.requires_grad_()\n",
        "        return q_out\n",
        "\n",
        "\n",
        "network = Net()\n",
        "optimizer = optim.SGD(network.parameters(), lr=0.001, momentum=0.9)\n",
        "epochs = 100\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss_list = []\n",
        "# for data,j in dataloaders[‘train’]: print(data)\n",
        "\n",
        "# %%\n",
        "for epoch in range(epochs):\n",
        "    total_loss = []\n",
        "    target_list = []\n",
        "    for data, target in dataloaders['train']:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        target_list.append(target.item())\n",
        "        optimizer.zero_grad()\n",
        "        output = network(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update quantum parameters\n",
        "        gradient = apply_gradient(network.q_params)\n",
        "        outlist = output.tolist()[0]\n",
        "        out = (1-outlist[0]) if outlist[0] > outlist[1] else outlist[1]\n",
        "        new_params = nn.Parameter(network.q_params - (0.001 * (out-target.item()) * gradient))\n",
        "        network.q_params = new_params\n",
        "        total_loss.append(loss.item())\n",
        "    loss_list.append(sum(total_loss) / len(total_loss))\n",
        "    print('Loss = {:.2f} after epoch #{:2d}'.format(loss_list[-1], epoch + 1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
